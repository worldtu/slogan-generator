{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 03:12:25.582039: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-27 03:12:25.595214: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748315545.611827    4091 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748315545.617191    4091 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748315545.629402    4091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748315545.629413    4091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748315545.629414    4091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748315545.629416    4091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-27 03:12:25.634006: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, SimpleRNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('valid.csv')\n",
    "test_set = pd.read_csv('test-curated.csv')\n",
    "\n",
    "SEED = 123\n",
    "train_set, validation_set = train_test_split(train_set, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESC_COL = 'desc'\n",
    "SLOGAN_COL = 'output'\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s.,?!']\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_set, validation_set, test_set]:\n",
    "    df[DESC_COL + '_cleaned'] = df[DESC_COL].apply(clean_text)\n",
    "    df[SLOGAN_COL + '_cleaned'] = df[SLOGAN_COL].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = 'facebook/bart-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def tokenize_text_with_transformers(text_series, tokenizer_model, max_len=128):\n",
    "    encoded_inputs = tokenizer_model(\n",
    "        text_series.tolist(),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    return encoded_inputs['input_ids']\n",
    "\n",
    "for df in [train_set, validation_set, test_set]:\n",
    "    df[DESC_COL + '_tokenized'] = tokenize_text_with_transformers(df[DESC_COL + '_cleaned'], tokenizer)\n",
    "    df[SLOGAN_COL + '_tokenized'] = tokenize_text_with_transformers(df[SLOGAN_COL + '_cleaned'], tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "required_desc_col = DESC_COL + '_tokenized'\n",
    "required_slogan_col = SLOGAN_COL + '_tokenized'\n",
    "\n",
    "def create_tf_dataset(df, desc_col_name, slogan_col_name, batch_size, shuffle=False, shuffle_buffer_size=None):\n",
    "    encoder_inputs = np.array(list(df[desc_col_name]), dtype=np.int32)\n",
    "    raw_slogans = np.array(list(df[slogan_col_name]), dtype=np.int32)\n",
    "\n",
    "    decoder_inputs = raw_slogans[:, :-1]\n",
    "    decoder_targets = raw_slogans[:, 1:]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((encoder_inputs, decoder_inputs), decoder_targets))\n",
    "    if shuffle:\n",
    "        if shuffle_buffer_size is None:\n",
    "            shuffle_buffer_size = len(df)\n",
    "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748315551.754966    4091 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22335 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:8d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_tf_dataset = create_tf_dataset(\n",
    "        train_set,\n",
    "        required_desc_col,\n",
    "        required_slogan_col,\n",
    "        BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        shuffle_buffer_size=1000\n",
    "    )\n",
    "    \n",
    "val_tf_dataset = create_tf_dataset(\n",
    "        validation_set,\n",
    "        required_desc_col,\n",
    "        required_slogan_col,\n",
    "        BATCH_SIZE\n",
    "    )\n",
    "test_tf_dataset = create_tf_dataset(\n",
    "        test_set,\n",
    "        required_desc_col,\n",
    "        required_slogan_col,\n",
    "        BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "rnn_units = 256\n",
    "\n",
    "input_vocab_size = tokenizer.vocab_size\n",
    "max_input_len = 128 \n",
    "target_vocab_size = tokenizer.vocab_size\n",
    "max_target_len_for_decoder_input = max_input_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(max_input_len,), name='encoder_input')\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(input_vocab_size, embedding_dim, name='encoder_embedding')\n",
    "encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
    "encoder_rnn = tf.keras.layers.SimpleRNN(rnn_units, return_state=True, name='encoder_rnn')\n",
    "encoder_outputs, encoder_state_h = encoder_rnn(encoder_embedding)\n",
    "encoder_states = [encoder_state_h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(max_target_len_for_decoder_input,), name='decoder_input') # For teacher forcing\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(target_vocab_size, embedding_dim, name='decoder_embedding')\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_rnn = tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, return_state=True, name='decoder_rnn')\n",
    "# Initial state for the decoder RNN is the encoder's final hidden state\n",
    "decoder_rnn_outputs, _ = decoder_rnn(decoder_embedding, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "decoder_dense = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Dense(target_vocab_size, activation='softmax'), name='decoder_output'\n",
    ")\n",
    "decoder_outputs = decoder_dense(decoder_rnn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "    raw_loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 1), tf.float32)\n",
    "    masked_loss = raw_loss * mask\n",
    "\n",
    "    return tf.reduce_sum(masked_loss) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,433,920</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,433,920</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_rnn         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ encoder_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_rnn         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>,      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ decoder_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_rnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>,       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,918,105</span> │ decoder_rnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50265</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m6,433,920\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m6,433,920\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_rnn         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │     \u001b[38;5;34m98,560\u001b[0m │ encoder_embeddin… │\n",
       "│ (\u001b[38;5;33mSimpleRNN\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_rnn         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m,      │     \u001b[38;5;34m98,560\u001b[0m │ decoder_embeddin… │\n",
       "│ (\u001b[38;5;33mSimpleRNN\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_rnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m,       │ \u001b[38;5;34m12,918,105\u001b[0m │ decoder_rnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m50265\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,983,065</span> (99.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,983,065\u001b[0m (99.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,983,065</span> (99.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,983,065\u001b[0m (99.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "def token_level_f1(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_true = tf.cast(y_true, tf.int64)\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)  \n",
    "\n",
    "    tp = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, y_pred), tf.not_equal(y_true, 0)), tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast(tf.logical_and(tf.not_equal(y_true, y_pred), tf.not_equal(y_pred, 0)), tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(tf.logical_and(tf.not_equal(y_true, y_pred), tf.not_equal(y_true, 0)), tf.float32))\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return f1\n",
    "\n",
    "training_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss= masked_sparse_categorical_crossentropy,\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        token_level_f1\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748315557.764610    4184 service.cc:152] XLA service 0x722e78002330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748315557.764650    4184 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-05-27 03:12:37.971011: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-27 03:12:38.725109: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/masked_sparse_categorical_crossentropy/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1748315559.481750    4184 cuda_dnn.cc:529] Loaded cuDNN version 90701\n",
      "2025-05-27 03:12:43.880399: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_60', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-27 03:12:46.876191: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_61', 600 bytes spill stores, 512 bytes spill loads\n",
      "\n",
      "2025-05-27 03:12:46.999243: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_61', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-05-27 03:12:47.143679: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_61', 740 bytes spill stores, 612 bytes spill loads\n",
      "\n",
      "2025-05-27 03:13:05.589492: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'loop_add_fusion_9', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "I0000 00:00:1748315585.771466    4184 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.0068 - loss: 9.1445 - token_level_f1: 0.0068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 03:13:15.740106: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/masked_sparse_categorical_crossentropy/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-05-27 03:13:21.668346: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_60', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-27 03:13:23.632240: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_61', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-05-27 03:13:23.705924: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_61', 440 bytes spill stores, 440 bytes spill loads\n",
      "\n",
      "2025-05-27 03:13:23.762788: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_61', 400 bytes spill stores, 400 bytes spill loads\n",
      "\n",
      "2025-05-27 03:13:23.918588: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_61', 492 bytes spill stores, 492 bytes spill loads\n",
      "\n",
      "2025-05-27 03:13:43.407867: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'loop_add_fusion_9', 536 bytes spill stores, 536 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_multiply_fusion_1', 108 bytes spill stores, 104 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_multiply_fusion_2', 76 bytes spill stores, 76 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_multiply_fusion', 88 bytes spill stores, 84 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_multiply_fusion_4', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.0069 - loss: 9.1301 - token_level_f1: 0.0069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 03:13:45.682915: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/masked_sparse_categorical_crossentropy/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2025-05-27 03:13:51.294458: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/masked_sparse_categorical_crossentropy/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 746ms/step - accuracy: 0.0069 - loss: 9.1162 - token_level_f1: 0.0069 - val_accuracy: 0.0081 - val_loss: 7.3663 - val_token_level_f1: 0.0081\n",
      "Epoch 2/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0082 - loss: 6.8445 - token_level_f1: 0.0082 - val_accuracy: 0.0086 - val_loss: 7.1358 - val_token_level_f1: 0.0085\n",
      "Epoch 3/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0086 - loss: 6.5903 - token_level_f1: 0.0086 - val_accuracy: 0.0087 - val_loss: 7.0291 - val_token_level_f1: 0.0087\n",
      "Epoch 4/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0088 - loss: 6.3861 - token_level_f1: 0.0088 - val_accuracy: 0.0086 - val_loss: 7.0036 - val_token_level_f1: 0.0086\n",
      "Epoch 5/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0090 - loss: 6.2065 - token_level_f1: 0.0090 - val_accuracy: 0.0088 - val_loss: 6.9684 - val_token_level_f1: 0.0088\n",
      "Epoch 6/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0092 - loss: 6.0559 - token_level_f1: 0.0092 - val_accuracy: 0.0087 - val_loss: 6.9441 - val_token_level_f1: 0.0087\n",
      "Epoch 7/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.0095 - loss: 5.8627 - token_level_f1: 0.0095 - val_accuracy: 0.0086 - val_loss: 6.9192 - val_token_level_f1: 0.0086\n",
      "Epoch 8/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0100 - loss: 5.7054 - token_level_f1: 0.0100 - val_accuracy: 0.0088 - val_loss: 6.8896 - val_token_level_f1: 0.0088\n",
      "Epoch 9/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0104 - loss: 5.5177 - token_level_f1: 0.0104 - val_accuracy: 0.0090 - val_loss: 6.8771 - val_token_level_f1: 0.0090\n",
      "Epoch 10/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0110 - loss: 5.3418 - token_level_f1: 0.0110 - val_accuracy: 0.0095 - val_loss: 6.8754 - val_token_level_f1: 0.0095\n",
      "Epoch 11/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0117 - loss: 5.1674 - token_level_f1: 0.0117 - val_accuracy: 0.0095 - val_loss: 6.8770 - val_token_level_f1: 0.0095\n",
      "Epoch 12/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0124 - loss: 4.9930 - token_level_f1: 0.0124 - val_accuracy: 0.0097 - val_loss: 6.8925 - val_token_level_f1: 0.0097\n",
      "Epoch 13/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.0129 - loss: 4.8553 - token_level_f1: 0.0129 - val_accuracy: 0.0098 - val_loss: 6.9004 - val_token_level_f1: 0.0098\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=3, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history = training_model.fit(\n",
    "    train_tf_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_tf_dataset,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /venv/main/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /venv/main/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /venv/main/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /venv/main/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in /venv/main/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /venv/main/lib/python3.12/site-packages (from rouge-score) (2.2.2)\n",
      "Requirement already satisfied: nltk in /venv/main/lib/python3.12/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.12/site-packages (from rouge-score) (2.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /venv/main/lib/python3.12/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /venv/main/lib/python3.12/site-packages (from nltk->rouge-score) (8.2.1)\n",
      "Requirement already satisfied: joblib in /venv/main/lib/python3.12/site-packages (from nltk->rouge-score) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /venv/main/lib/python3.12/site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.12/site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tokens(tokenizer, token_ids):\n",
    "    tokens = [id for id in token_ids if id != tokenizer.pad_token_id and id != tokenizer.eos_token_id]\n",
    "    return tokenizer.decode(tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 445ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "theprise your,k\n",
      "eliquid testing uk\n"
     ]
    }
   ],
   "source": [
    "pred_texts = []\n",
    "true_texts = []\n",
    "i = 0\n",
    "for (encoder_input, decoder_input), decoder_target in test_tf_dataset:\n",
    "    if i == 4:\n",
    "        break\n",
    "    preds = training_model.predict([encoder_input, decoder_input])\n",
    "    pred_ids = preds.argmax(-1)\n",
    "    for j in range(pred_ids.shape[0]):\n",
    "        pred_texts.append(decode_tokens(tokenizer, pred_ids[i]))\n",
    "        true_texts.append(decode_tokens(tokenizer, decoder_target[i].numpy()))\n",
    "    i += 1\n",
    "print(pred_texts[0])\n",
    "print(true_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_texts = []\n",
    "# true_texts = []\n",
    "\n",
    "# for (encoder_input, decoder_input), decoder_target in test_tf_dataset:\n",
    "#     preds = training_model.predict([encoder_input, decoder_input])\n",
    "#     pred_ids = preds.argmax(-1)\n",
    "#     for i in range(pred_ids.shape[0]):\n",
    "#         pred_texts.append(decode_tokens(tokenizer, pred_ids[i]))\n",
    "#         true_texts.append(decode_tokens(tokenizer, decoder_target[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theprise your,k', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'theustainable for the and marketing', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'the and business business and the business future', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and', 'theardative and and the and']\n"
     ]
    }
   ],
   "source": [
    "print(pred_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['Easily deliver personalized activities that enrich the lives of residents in older adult communities. Save time and increase satisfaction.',\n",
    "'Powerful lead generation software that converts abandoning visitors into subscribers with our dynamic marketing tools and Exit Intent® technology.',\n",
    "\"Twine matches companies to the best digital and creative freelancers from a network of over 260,000. It's free to post a job and you only pay when you hire.\",\n",
    "\"Looking for fresh web design & development? Need new marketing materials or a smart campaign to drive business? How about a video or updated photos? Let's talk and tell the world your story.\",\n",
    "# --- test-curated.csv\n",
    "'Our expert team of Analytical Chemists provide eLiquid analysis & manufacturing services, ensuring full regulatory compliance for the e-cigarette market.',\n",
    "'From placing entire software engineering teams to integrating easily into your current team, we offer bespoke placements of the very best engineers.',\n",
    "'Turning ideas into visual content since 1999. Content Creation Studio in Ghent. Branded content - corporate video - visuals for events - 360 video',\n",
    "'World market leader for robotic vision systems, inline measurement technology & inspection technology. We are your partner at over 25 locations worldwide.',\n",
    "# --- other examples\n",
    "'People and projects for sustainable change. Experts in sustainability recruitment, we recruit exceptional people into roles working on sustainability projects or in ethical and responsible organisations.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.8734576e-07 1.8342716e-07 1.7764331e-04 ... 1.7861251e-07\n",
      "   1.7817699e-07 1.6502331e-07]\n",
      "  [6.2433728e-08 6.4332156e-08 2.0050879e-04 ... 5.6496720e-08\n",
      "   6.8199931e-08 5.3223683e-08]\n",
      "  [3.7897703e-08 4.0170516e-08 4.4989216e-04 ... 3.8002803e-08\n",
      "   4.0246746e-08 3.4963413e-08]\n",
      "  ...\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]\n",
      "  [2.7318801e-09 2.7340952e-09 6.5169811e-01 ... 2.6485714e-09\n",
      "   2.6914504e-09 2.2888884e-09]]]\n",
      "[[[1.8734576e-07 1.8342716e-07 1.7764331e-04 ... 1.7861251e-07\n",
      "   1.7817699e-07 1.6502331e-07]\n",
      "  [6.4514332e-08 7.1649204e-08 4.4800981e-06 ... 6.3175648e-08\n",
      "   7.1098405e-08 5.7638221e-08]\n",
      "  [4.3086434e-08 4.2886953e-08 1.1097053e-03 ... 4.2116444e-08\n",
      "   4.3483006e-08 3.8520941e-08]\n",
      "  ...\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]]]\n",
      "[[[1.8734576e-07 1.8342716e-07 1.7764331e-04 ... 1.7861251e-07\n",
      "   1.7817699e-07 1.6502331e-07]\n",
      "  [6.4514332e-08 7.1649204e-08 4.4800981e-06 ... 6.3175648e-08\n",
      "   7.1098405e-08 5.7638221e-08]\n",
      "  [9.6930258e-08 9.7001831e-08 1.2776309e-04 ... 9.6414247e-08\n",
      "   1.0035071e-07 8.8606328e-08]\n",
      "  ...\n",
      "  [2.7318798e-09 2.7340950e-09 6.5169805e-01 ... 2.6485711e-09\n",
      "   2.6914502e-09 2.2888837e-09]\n",
      "  [2.7318852e-09 2.7340952e-09 6.5169811e-01 ... 2.6485714e-09\n",
      "   2.6914451e-09 2.2888840e-09]\n",
      "  [2.7318852e-09 2.7340952e-09 6.5169811e-01 ... 2.6485714e-09\n",
      "   2.6914451e-09 2.2888884e-09]]]\n",
      "[[[1.8734576e-07 1.8342716e-07 1.7764331e-04 ... 1.7861251e-07\n",
      "   1.7817699e-07 1.6502331e-07]\n",
      "  [6.4514332e-08 7.1649204e-08 4.4800981e-06 ... 6.3175648e-08\n",
      "   7.1098405e-08 5.7638221e-08]\n",
      "  [9.6930258e-08 9.7001831e-08 1.2776309e-04 ... 9.6414247e-08\n",
      "   1.0035071e-07 8.8606328e-08]\n",
      "  ...\n",
      "  [2.7318801e-09 2.7340952e-09 6.5169811e-01 ... 2.6485714e-09\n",
      "   2.6914504e-09 2.2888884e-09]\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]]]\n",
      "[[[1.8734576e-07 1.8342716e-07 1.7764331e-04 ... 1.7861251e-07\n",
      "   1.7817699e-07 1.6502331e-07]\n",
      "  [6.4514332e-08 7.1649204e-08 4.4800981e-06 ... 6.3175648e-08\n",
      "   7.1098405e-08 5.7638221e-08]\n",
      "  [9.6930258e-08 9.7001831e-08 1.2776309e-04 ... 9.6414247e-08\n",
      "   1.0035071e-07 8.8606328e-08]\n",
      "  ...\n",
      "  [2.7318798e-09 2.7340950e-09 6.5169805e-01 ... 2.6485711e-09\n",
      "   2.6914448e-09 2.2888882e-09]\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]\n",
      "  [2.7318838e-09 2.7340989e-09 6.5169775e-01 ... 2.6485698e-09\n",
      "   2.6914488e-09 2.2888871e-09]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the best your business'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"Twine matches companies to the best digital and creative freelancers from a network of over 260,000. It's free to post a job and you only pay when you hire.\"\n",
    "greedy_generate(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESC : Easily deliver personalized activities that enrich the lives of residents in older adult c…\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n",
      "DESC : Powerful lead generation software that converts abandoning visitors into subscribers with …\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n",
      "DESC : Twine matches companies to the best digital and creative freelancers from a network of ove…\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n",
      "DESC : Looking for fresh web design & development? Need new marketing materials or a smart campai…\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n",
      "DESC : Our expert team of Analytical Chemists provide eLiquid analysis & manufacturing services, …\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n",
      "DESC : From placing entire software engineering teams to integrating easily into your current tea…\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n",
      "DESC : Turning ideas into visual content since 1999. Content Creation Studio in Ghent. Branded co…\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n",
      "DESC : World market leader for robotic vision systems, inline measurement technology & inspection…\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n",
      "DESC : People and projects for sustainable change. Experts in sustainability recruitment, we recr…\n",
      "SLOG : the best your business\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "PAD_ID = tokenizer.pad_token_id\n",
    "BOS_ID = tokenizer.bos_token_id\n",
    "EOS_ID = tokenizer.eos_token_id\n",
    "\n",
    "max_input_len   = training_model.input[0].shape[1]\n",
    "max_target_len  = training_model.input[1].shape[1]\n",
    "\n",
    "def encode_description(text):\n",
    "    \"\"\"Tokenise + pad / truncate to max_input_len.\"\"\"\n",
    "    ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    ids = ids[:max_input_len]                      # truncate\n",
    "    pad_len = max_input_len - len(ids)\n",
    "    return np.asarray(ids + [PAD_ID] * pad_len, dtype=np.int32)\n",
    "\n",
    "def greedy_generate(description, max_dec_len=max_target_len):\n",
    "    \"\"\"Generate one slogan with greedy decoding.\"\"\"\n",
    "    enc_inp = encode_description(description)[None, :]\n",
    "\n",
    "    dec_ids = [BOS_ID]\n",
    "\n",
    "    for _ in range(max_dec_len - 1):\n",
    "        dec_inp = np.asarray(dec_ids + [PAD_ID] * (max_dec_len - len(dec_ids)),\n",
    "                             dtype=np.int32)[None, :]\n",
    "\n",
    "        logits = training_model.predict([enc_inp, dec_inp], verbose=0)\n",
    "        next_id = int(np.argmax(logits[0, len(dec_ids)-1]))\n",
    "        \n",
    "        if next_id == EOS_ID:\n",
    "            break\n",
    "        dec_ids.append(next_id)\n",
    "\n",
    "    return decode_tokens(tokenizer, dec_ids[1:])\n",
    "\n",
    "for txt in examples:\n",
    "    print(\"DESC :\", txt[:90] + (\"…\" if len(txt) > 90 else \"\"))\n",
    "    print(\"SLOG :\", greedy_generate(txt))\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <pad>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token_id, tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 9.659641134380428e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/venv/main/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/venv/main/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "references = [[nltk.word_tokenize(ref)] for ref in true_texts] \n",
    "candidates = [nltk.word_tokenize(pred) for pred in pred_texts]\n",
    "\n",
    "bleu = corpus_bleu(references, candidates)\n",
    "print('BLEU:', bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.10795454545454544\n",
      "ROUGE-2: 0.0\n",
      "ROUGE-L: 0.10795454545454544\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge1_list, rouge2_list, rougel_list = [], [], []\n",
    "\n",
    "for ref, pred in zip(true_texts, pred_texts):\n",
    "    scores = scorer.score(ref, pred)\n",
    "    rouge1_list.append(scores['rouge1'].fmeasure)\n",
    "    rouge2_list.append(scores['rouge2'].fmeasure)\n",
    "    rougel_list.append(scores['rougeL'].fmeasure)\n",
    "\n",
    "print('ROUGE-1:', sum(rouge1_list)/len(rouge1_list))\n",
    "print('ROUGE-2:', sum(rouge2_list)/len(rouge2_list))\n",
    "print('ROUGE-L:', sum(rougel_list)/len(rougel_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from the previous example\n",
    "epochs = list(range(1, 28)) \n",
    "training_loss = [\n",
    "    4.4428, 0.4468, 0.4195, 0.4061, 0.3957, 0.3839, 0.3748, 0.3609, 0.3503, 0.3350,\n",
    "    0.3229, 0.3077, 0.2971, 0.2832, 0.2689, 0.2564, 0.2437, 0.2315, 0.2191, 0.2077,\n",
    "    0.1965, 0.1867, 0.1756, 0.1675, 0.1587, 0.1514, 0.1435\n",
    "]\n",
    "validation_loss = [\n",
    "    0.4670, 0.4281, 0.4187, 0.4112, 0.4043, 0.3970, 0.3904, 0.3828, 0.3746, 0.3680,\n",
    "    0.3612, 0.3555, 0.3497, 0.3435, 0.3377, 0.3322, 0.3270, 0.3215, 0.3166, 0.3117,\n",
    "    0.3071, 0.3018, 0.2975, 0.2928, 0.2891, 0.2854\n",
    "]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(epochs[:len(training_loss)], training_loss, label='Training Loss', color='orange', marker='o', linestyle='-')\n",
    "\n",
    "# Plot validation loss\n",
    "plt.plot(epochs[:len(validation_loss)], validation_loss, label='Validation Loss', color='orangered', marker='o', linestyle='-')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Training and Validation Loss by Epoch', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, linestyle='--', alpha=0.7, color='lightgrey')\n",
    "\n",
    "# Adjust y-axis if your data is in a similar range to the image\n",
    "# For the provided data, the loss is much lower. If your data matches the image's scale (e.g. 5-10):\n",
    "# plt.ylim(5, max(max(training_loss, default=5), max(validation_loss, default=5)) * 1.05) \n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Customize tick parameters for a cleaner look\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
